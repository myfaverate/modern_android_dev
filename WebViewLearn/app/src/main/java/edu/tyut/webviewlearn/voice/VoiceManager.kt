package edu.tyut.webviewlearn.voice

import android.annotation.SuppressLint
import android.content.Context
import android.content.pm.PackageManager
import android.media.AudioFormat
import android.media.AudioRecord
import android.media.MediaRecorder
import android.net.Uri
import android.os.Environment
import android.util.Log
import androidx.core.content.ContextCompat
import androidx.core.content.FileProvider
import kotlinx.coroutines.Dispatchers
import kotlinx.coroutines.withContext
import okio.BufferedSink
import okio.BufferedSource
import okio.buffer
import okio.sink
import okio.source
import java.io.File
import java.nio.ByteBuffer
import java.nio.ByteOrder

private const val TAG: String = "VoiceManager"

/**
 * http://soundfile.sapp.org/doc/WaveFormat/
 * âœ… ä¸€å¥è¯ç†è§£
 * WAV æ–‡ä»¶ = 44 å­—èŠ‚ WAV Header + åŽŸå§‹ PCM æ•°æ®
 *
 * ðŸ§© WAV æ–‡ä»¶å¤´æ ¼å¼
 * å­—æ®µ	é•¿åº¦	å†…å®¹
 *
 * RIFF	4 bytes	"RIFF" å­—ç¬¦ä¸²
 * æ–‡ä»¶å¤§å°	4 bytes	36 + PCM æ•°æ®å¤§å°
 * WAVE	4 bytes	"WAVE" å­—ç¬¦ä¸²
 * fmt	4 bytes	"fmt "
 * å­å—1å¤§å°	4 bytes	16ï¼ˆPCMï¼‰
 * éŸ³é¢‘æ ¼å¼	2 bytes	1ï¼ˆPCMï¼‰
 * å£°é“æ•°	2 bytes	1 = mono, 2 = stereo
 * é‡‡æ ·çŽ‡	4 bytes	eg. 44100
 * å­—èŠ‚çŽ‡	4 bytes	= é‡‡æ ·çŽ‡ Ã— å£°é“æ•° Ã— æ¯æ ·æœ¬å­—èŠ‚æ•°
 * æ¯å¸§å­—èŠ‚æ•°	2 bytes	= å£°é“æ•° Ã— æ¯æ ·æœ¬å­—èŠ‚æ•°
 * æ¯æ ·æœ¬ä½æ•°	2 bytes	eg. 16
 * data	4 bytes	"data"
 * æ•°æ®å¤§å°	4 bytes	PCM æ•°æ®å­—èŠ‚æ•°
 *
 */
@SuppressLint("MissingPermission")
internal class VoiceManager {

    private val channelMask: Int = AudioFormat.CHANNEL_IN_MONO
    private val sampleRate = 16000
    private val bufferSize: Int = AudioRecord.getMinBufferSize(sampleRate, channelMask, AudioFormat.ENCODING_PCM_16BIT)

    private val audioRecord: AudioRecord by lazy {
        // æ²¡æœ‰æƒé™ä¸èƒ½è¿›è¡Œåˆå§‹åŒ–æ³¨æ„è®°ä½
        AudioRecord.Builder()
            .setAudioSource(MediaRecorder.AudioSource.MIC)
            .setAudioFormat(AudioFormat.Builder().setEncoding(AudioFormat.ENCODING_PCM_16BIT).setSampleRate(sampleRate).setChannelMask(channelMask).build())
            .setBufferSizeInBytes(bufferSize)
            .build()
    }

    internal val isRecording: Boolean get() = audioRecord.recordingState == AudioRecord.RECORDSTATE_RECORDING

    internal suspend fun startRecord(context: Context, uri: Uri) = withContext(context = Dispatchers.IO) {

        val wavUri: Uri = FileProvider.getUriForFile(context, "${context.packageName}.provider",  File("${Environment.getExternalStoragePublicDirectory(Environment.DIRECTORY_DOWNLOADS)}/hello.wav"))

        audioRecord.startRecording()
        var totalLength = 0
        val bytes = ByteArray(bufferSize)
        var length: Int
        context.contentResolver.openOutputStream(uri)?.sink()?.buffer()?.use { bufferedSink: BufferedSink ->
            while (audioRecord.read(bytes, 0, bytes.size).also { length = it } > 0){
                bufferedSink.write(bytes, 0, length)
                totalLength += length
                Log.i(TAG, "startRecord -> data: ${bytes.joinToString()}")
            }
            // å†™å…¥wavå¤´
            bufferedSink.flush()
            Log.i(TAG, "startRecord -> å½•åˆ¶å®Œæˆ...")
        }
        context.contentResolver?.openInputStream(uri)?.source()?.buffer()?.use { bufferedSource: BufferedSource ->
            context.contentResolver.openOutputStream(wavUri)?.sink()?.buffer()?.use { bufferedSink: BufferedSink ->
                val wavHeader: ByteArray = writeWavHeader(totalLength = totalLength)
                bufferedSink.write(source = wavHeader)
                bufferedSource.readAll(sink = bufferedSink)
                bufferedSink.flush()
            }
        }
    }

    private fun writeWavHeader(
        totalLength: Int,
        channels: Int = 1, // mono
        bitsPerSample: Int = 16,
    ): ByteArray {
        val header = ByteArray(44)
        val buffer: ByteBuffer = ByteBuffer.wrap(header).order(ByteOrder.LITTLE_ENDIAN)

        buffer.put("RIFF".toByteArray(Charsets.US_ASCII))       // Chunk ID
        buffer.putInt(totalLength + 36)                             // Chunk Size
        buffer.put("WAVE".toByteArray(Charsets.US_ASCII))       // Format
        buffer.put("fmt ".toByteArray(Charsets.US_ASCII))       // Subchunk1 ID
        buffer.putInt(16)                                       // Subchunk1 Size
        buffer.putShort(1)                                      // Audio format = PCM
        buffer.putShort(1)                     // Channels
        buffer.putInt(sampleRate)                               // Sample rate
        buffer.putInt(sampleRate * 1 * bitsPerSample / 8)                                 // Byte rate
        buffer.putShort((1 * bitsPerSample / 8).toShort()) // Block align
        buffer.putShort(bitsPerSample.toShort())                // Bits per sample
        buffer.put("data".toByteArray(Charsets.US_ASCII))       // Subchunk2 ID
        buffer.putInt(totalLength)                            // Subchunk2 size
        return header
    }

    internal fun stopRecord(){
        if (audioRecord.recordingState == AudioRecord.RECORDSTATE_RECORDING){
            audioRecord.stop()
        }
    }

    internal fun release(){
        if (audioRecord.recordingState == AudioRecord.RECORDSTATE_RECORDING){
            audioRecord.stop()
        }
        audioRecord.release()
    }

}